{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 6 \n",
    "\n",
    "# Recognizing Face and Doing Multiple Tasks After It"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Creating Training DataSet For ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-4-7134f2cf75b3>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "---- SAMPLE IMAGES COLLECTED ----\n",
      "---- READY FOR TRAINING ----\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Loading HaarCascade face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#Defining Function\n",
    "def face_extractor(img):\n",
    "    #Function detects faces and return the cropped faces\n",
    "    #If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    # converting RGB colors of image to B&W or GRAY\n",
    "    faces=face_classifier.detectMultiScale(gray, 1.3, 5)  \n",
    "    # used for detecting face , here 1.3 is scaling factor and 5 is no. of nearest neighbours\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h , x:x+w]\n",
    "        \n",
    "    return cropped_face\n",
    "\n",
    "# Initializing webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samles of your face from webcam input\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize( face_extractor(frame), (200 , 200) )\n",
    "        face = cv2.cvtColor( face, cv2.COLOR_BGR2GRAY )\n",
    "        \n",
    "        #save file in specified directory with unique name\n",
    "        file_name_path = r'C:\\Users\\ABHISHEK VERMA\\Desktop\\cv-sp\\Face-Recognition--main\\Face-Recognition--main\\abhishek\\imgesdatset-1/' + str(count) + '.jpg'\n",
    "        cv2.imwrite( file_name_path, face)\n",
    "        \n",
    "        #put count on images and display live count\n",
    "        cv2.putText( face , str(count), (50,50), cv2.FONT_HERSHEY_SCRIPT_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow( 'Face cropper', face )\n",
    "        \n",
    "    else:\n",
    "        print('Face Not Found')\n",
    "        pass\n",
    "    if cv2.waitKey(1) == 13 or count == 200:  # 13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"---- SAMPLE IMAGES COLLECTED ----\")\n",
    "print(\"---- READY FOR TRAINING ----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile , join\n",
    "\n",
    "\n",
    "# Get the trainig data we made previously\n",
    "data_path = r'C:\\Users\\ABHISHEK VERMA\\Desktop\\cv-sp\\Face-Recognition--main\\Face-Recognition--main\\abhishek\\imgesdatset-1/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile ( join ( data_path, f ) ) ]\n",
    "\n",
    "# Create array for training Data and labels\n",
    "Training_Data , Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "# model = cv2.createLBPHFaceRecognizer()\n",
    "recognizer  = cv2.face.LBPHFaceRecognizer_create()\n",
    "# Let's train our model \n",
    "recognizer.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Step 3 - Run Our Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-12-8fa816dc257d>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n",
      "OpenCV(4.5.2) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pywhatkit\n",
    "import subprocess as sp\n",
    "import webbrowser as wb\n",
    "import smtplib\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = recognizer.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_SCRIPT_COMPLEX, 1, (255,120,150), 2)\n",
    "        if confidence > 85:\n",
    "            cv2.putText(image, \"HY Abhishek Verma \", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            #This will launch instance in aws with name production\n",
    "            a = sp.getstatusoutput(\"aws ec2 run-instances --image-id ami-0ad704c126371a549 --subnet-id subnet-59f8f131 --instance-type t2.micro  --count 1  --security-group-ids sg-d3da70b4 --key-name mykeytoaws --tag-specifications ResourceType=instance,Tags=[{Key=Name,Value=Production}] \")\n",
    "            print(a[1])\n",
    "            text1 ='\"--------------New Instance Launched successfully----------------\"'\n",
    "            print(text1)\n",
    "            wb.open(\"https://ap-south-1.console.aws.amazon.com/ec2/v2/home?region=ap-south-1#Instances:\")   \n",
    "            #This will launch external ebs  volume in aws with name external\n",
    "            b = sp.getstatusoutput(\"aws ec2 create-volume --availability-zone ap-south-1a --volume-type gp2 --size 5 --tag-specifications ResourceType=volume,Tags=[{Key=Name,Value=ExternalVolume}]\")\n",
    "            print(b[1])\n",
    "            text2 ='--------------New voume created successfully----------------'\n",
    "            print(text2)\n",
    "            wb.open(\"https://ap-south-1.console.aws.amazon.com/ec2/v2/home?region=ap-south-1#Volumes:sort=desc:createTime\")            \n",
    "            volume_id = input(\"enter volume id:\")\n",
    "            instance_id =input(\"enter instance id:\")\n",
    "            #This will attach external volumewith aws instance.\n",
    "            c=sp.getstatusoutput(\"aws ec2 attach-volume --volume-id {} --instance-id {} --device /dev/sdf\".format(volume_id,instance_id))\n",
    "            print(c[1])\n",
    "            text3 =\"--------------New voume Added to Instance successfully----------------\"\n",
    "            print(text3)\n",
    "            wb.open(\"https://ap-south-1.console.aws.amazon.com/ec2/v2/home?region=ap-south-1#Instances:\")       \n",
    "            break    \n",
    "        else:\n",
    "            cv2.putText(image, \" Stanger \", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            cv2.waitKey() == 13\n",
    "\n",
    "            # Python code to illustrate Sending mail from \n",
    "            # your Gmail account \n",
    "            \n",
    "\n",
    "            # creates SMTP session\n",
    "            s = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "\n",
    "            # start TLS for security\n",
    "            #s.starttls()\n",
    "\n",
    "            # Authentication\n",
    "            s.login(\"vermaabhishek.av109@gmail.com\", \"Google#$9\")\n",
    "\n",
    "            # message to be sent\n",
    "            message = \"Detected Stanger face From Python\"\n",
    "\n",
    "            # sending the mail\n",
    "            s.sendmail(\"vermaabhishek.av109@gmail.com\", \"abhishekverma.av109@gmail.com\", message)\n",
    "\n",
    "            # terminating the session\n",
    "            s.quit()\n",
    "            #pywhatkit.send_mail(\"vermaabhishek.av109@gmail.com\", \"Google#$9\", \"face recognition\", \"hello this is  Abhishek Verma\", \"abhishekverma.av109@gmail.com\")\n",
    "            #pywhatkit.sendwhatmsg_instantly(phone_no = \"+918xxxxxxxxx\", message = \"Hi, i sent you this message by Face Recognition \")\n",
    "            \n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
